# Nlp Bio Portuguese Chunking
## Uma API para extra√ß√£o de *chunks* (*Noun phrases*) em textos cl√≠nicos
### Porque "*Chunk Is All You Need*" üòÑüòÑüòÑ

# √çndice
1. [Sobre](#sobre)
2. [POS-Tagger](#pos-tagger)
3. [Como executar localmente](#como-executar-localmente-para-extrair-os-chunks)
4. [Executando via docker](#executando-via-docker)
5. [Como citar](#como-citar)

## Sobre

*Chunking* √© uma maneira de agrupar elementos sequenciais de um texto como frases, podendo ser frase nominal, frase verbal, frase preposicional etc, utilizando a sua parte do discurso (*POS-tag*). Ao contr√°rio do reconhecimento de entidade nomeada (NER ou REN), que encontra e classifica peda√ßos relevantes no texto.

Neste trabalho, extra√≠mos as frases nominais, ou seja, frases que t√™m um substantivo como cabe√ßa ("*Noun phrases*"). 

Utilizamos dois m√©todos para gerar o *POS-Tag* das sente√ßas:

1. A biblioteca `spacy` para tokenizar e extrair o *POS-tagger* de cada palavra da frase, com o *corpus* `pt_core_news_md`.
2. Um modelo *token-sequence* `BERT` treinado com o *corpus* [`MacMorpho`](http://nilc.icmc.usp.br/macmorpho/) usando como *checkpoint* o modelo [BioBERTpt](https://huggingface.co/pucpr/biobertpt-all), sendo este √∫ltimo treinado com textos cl√≠nicos e biom√©dicos em portugu√™s.

Na sequencia, criamos uma fun√ß√£o que extrai todos os substantivos da frase, mantendo-o junto com os seus complementos (adjetivos, adv√©rbios, etc).

Exemplo: 
```
---Frase original:---

Data de Cria√ß√£o do Documento: 22/04/2014   Dispneia importante aos esfor√ßos + dor tipo peso no peito no esfor√ßo. Obeso, has, icc  c # cintilografia miocardica para avaliar angina.


---Chunks da frase:---

['Data de Cria√ß√£o do Documento 22/04/2014', 'Dispneia importante aos esfor√ßos', 'dor tipo peso no peito no esfor√ßo', 'Obeso', 'has', 'icc', 'cintilografia miocardica', 'angina']
```

## POS-Tagger

Al√©m do modelo de *POS-tagger* fornecido pelo `spacy`, tamb√©m treinamos um modelo pr√≥prio a partir do *fine-tuning* do modelo de linguagem [BioBERTpt(all)](https://huggingface.co/pucpr/biobertpt-all) com o *corpus* para l√≠ngua portuguesa [MacMorpho](http://nilc.icmc.usp.br/macmorpho/), com 10 √©pocas, chegando em um *F1-Score* geral de **0.9818**.

Nosso modelo est√° no reposit√≥rio oficial do `Hugging Faces`, voc√™ pode acess√°-lo pelo endere√ßo: https://huggingface.co/pucpr-br/postagger-bio-portuguese.

<img src="img/postagger-huggingfaces.png">

Se voc√™ gostou do nosso trabalho, n√£o se esque√ßa de dar um *like* no modelo no `Hugging Faces` ‚ù§Ô∏è

Como usar o modelo de *POS-tagger* (sem o *chunking*):

```
from transformers import AutoTokenizer, AutoModelForTokenClassification

tokenizer = AutoTokenizer.from_pretrained("pucpr-br/postagger-bio-portuguese")

model = AutoModelForTokenClassification.from_pretrained("pucpr-br/postagger-bio-portuguese")
```

OBS: Caso voc√™ necessite outros modelos de POS-taggers para portugu√™s, na √°rea cl√≠nica ou biom√©dica, n√£o deixe de experimentar esses [modelos treinados com Flair](https://github.com/HAILab-PUCPR/portuguese-clinical-pos-tagger).

Aqui voc√™ tem um manual dos tipos gramaticais retornados pelo modelo:

| Sigla  |  Significado  |
| ------------------- | ------------------- |
|  ADJ |  Adjetivo |
|  ADV |  Adv√©rbio |
|  ADV-KS |  Adv√©rbio conjuntivo subordinado  |
|  ADV-KS-REL |   Adv√©rbio relativo subordinado |
|  ART |  Artigo  |
|  CUR |  Moeda  |
|  IN |  Interjei√ß√£o |
|  KC |  Conjun√ß√£o coordenativa |
|  KS |  Conjun√ß√£o subordinativa |
|  N |  Substantivo |
|  NPROP | Substantivo pr√≥prio |
|  NUM |  N√∫mero |
|  PCP |  Partic√≠pio |
|  PDEN |  Palavra denotativa |
|  PREP |  Preposi√ß√£o |
|  PROADJ |  Pronome Adjetivo |
|  PRO-KS |  Pronome conjuntivo subordinado |
|  PRO-KS-REL |  Pronome relativo conectivo subordinado |
|  PROPESS |  Pronome pessoal |
|  PROSUB |  Pronome nominal |
|  V | Verbo |
|  VAUX  | Verbo auxiliar |

Mais informa√ß√µes e exemplos em: http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf

## Como executar localmente para extrair os *chunks*

Para gerar os *chunks* (*noun phrases*), voc√™ pode executar diretamente pelos *notebooks* [com spacy](https://github.com/lisaterumi/nlp-portuguese-chunking/blob/main/notebook/chunking-portuguese_spacy.ipynb) e com o [POS-Tagger Bio Portuguese](https://github.com/lisaterumi/nlp-portuguese-chunking/blob/main/notebook/chunking-portuguese_postagger_biopt.ipynb)

Ou executar um servidor para ter acesso √† interface *web*, seguindo os passos abaixo (os exemplos a seguir s√£o com o uso da bilbioteca `spacy`, por ser um modelo mais leve de executar, principalmente dentro dos *containers*).

1. Clone o reposit√≥rio
2. Instale as biblitecas necess√°rias (se preferir, use [Anaconda](http://www.anaconda.com))
```
pip install flask == 4.3.0
pip install spacy == 2.3.7
```
ou atrav√©s do comnando:
```
pip install -r requirements.txt
```
3. Execute o `app.py` (est√° configurado para rodar na porta 5000)
```
python app.py
```
4. No navegador, acesse http://localhost:5000/

5. Escreve uma senten√ßa cl√≠nica ou selecione alguma frase de exemplo e clicar no bot√£o de pesquisa (lupa). 
 
Ser√£o retornadas os *chunks* identificados na senten√ßa de entrada. 
 
<img src="img/chunk.png">

## Executando via Docker

1. Para executar a API dentro de um *container* `Docker`, onde n√£o √© necess√°rio se preocupar com o ambiente e bibliotecas, basta seguir os passos:

1. Caso n√£o possua, instale o `Docker` seguindo [essas orienta√ß√µes](https://docs.docker.com/get-started/).

2. Execute os seguintes comandos (para executar o *container* na porta 5000)
```
docker build -t chunking .

docker run --name chunking_instance -p 0.0.0.0:5000:5000  -d chunking
```
Ou, se desejar execut√°-la diretamente da nossa [imagem no Dockerhub](https://hub.docker.com/r/terumi/chunking/tags):
```
docker run --name chunking_instance -p 0.0.0.0:5000:5000 -d terumi/chunking:version1
```
3. No navegador, acesse http://localhost:5000/

## Como citar

** *em breve* **

